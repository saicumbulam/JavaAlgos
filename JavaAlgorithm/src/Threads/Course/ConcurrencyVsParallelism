Serial Execution:
When programs are serially executed, they are scheduled one at a time on the CPU.
Once a task gets completed, the next one gets a chance to run.
Each task is run from the beginning to the end without interruption.


Concurrency:
A system capable of running several distinct programs or more than one
independent unit of the same program in overlapping time intervals is
called a concurrent system.

A concurrent system can have two programs in progress at the same time where
progress doesn't imply execution.
One program can be suspended while the other executes.
Both programs are able to make progress as their execution is interleaved.
In concurrent systems, the goal is to maximize throughput and minimize latency.

Parallelism:
A parallel system is one which necessarily has the ability to execute multiple programs at the same time.
In parallel systems the emphasis is on increasing throughput and optimizing usage of hardware resources.
The goal is to extract out as much computation speedup as possible.
Example problems include matrix multiplication, 3D rendering,
data analysis, and particle simulation.


Concurrency vs Parallelism
A concurrent system need not be parallel, whereas a parallel system is indeed concurrent.
Additionally, a system can be both concurrent and parallel e.g. a multitasking
operating system running on a multicore machine.
Concurrency is about dealing with lots of things at once.
Parallelism is about doing lots of things at once.


